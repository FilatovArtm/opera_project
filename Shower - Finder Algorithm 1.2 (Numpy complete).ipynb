{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run nbloader.py\n",
    "import seaborn\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from matplotlib import pylab as plt\n",
    "import root_numpy\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "%load_ext Cython\n",
    "\n",
    "\n",
    "BRICK_X = 124000\n",
    "BRICK_Y = 99000\n",
    "BRICK_Z = 75000\n",
    "SAFE_M = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing notebook from read_opera_bg.ipynb\n",
      "bg: 2767 tracks\n",
      "len(slopes): 2767\n"
     ]
    }
   ],
   "source": [
    "from read_opera_bg import plot_bg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing notebook from read_opera_mc.ipynb\n",
      "Warning: Cannot change to a different GUI toolkit: qt. Using osx instead.\n",
      "numtracks reduction by cuts:  [188, 186, 109, 50, 19, 19]\n",
      "bg: 27322110 tracks\n",
      "numtracks reduction by cuts:  [18724, 18678, 11058, 5389, 2799, 2684]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "from read_opera_bg import load_bg;\n",
    "from read_opera_mc import load_mc;\n",
    "pbg = load_bg(step=1);\n",
    "pmc = load_mc(step=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def centralize_shower(shower):\n",
    "    x_diff = shower['ele_x'] - 50000\n",
    "    y_diff = shower['ele_y'] - 40000\n",
    "    shower.loc['BT_X'] = shower.loc['BT_X'] - x_diff\n",
    "    shower.loc['BT_Y'] = shower.loc['BT_Y'] - y_diff\n",
    "    return shower\n",
    "\n",
    "\n",
    "def generate_training_sample(pmc, pbg):\n",
    "    z_coordinates = list(set(pbg['s.eZ']))\n",
    "    z_coordinates.sort()\n",
    "    def f(x): return x > 60000\n",
    "    z_coordinates = filter(f, z_coordinates)\n",
    "    \n",
    "    data_to_clear = pbg[pbg['s.eZ'].isin(z_coordinates)]\n",
    "    data_to_clear = data_to_clear.apply(np.random.permutation)\n",
    "    data_to_clear['signal'] = 0\n",
    "    data_to_clear = data_to_clear[:30000]\n",
    "    \n",
    "    \n",
    "    parents = list()\n",
    "    sons = list()\n",
    "\n",
    "    for i in range(400):\n",
    "        my_shower = pmc.iloc[i]\n",
    "        shower_frame = pd.DataFrame([\n",
    "            my_shower['BT_X'],\n",
    "            my_shower['BT_Y'],\n",
    "            my_shower['BT_Z'] - my_shower['BT_Z'] % 1293,\n",
    "            my_shower['BT_SX'],\n",
    "            my_shower['BT_SY']],\n",
    "            index=['s.eX', 's.eY', 's.eZ', 's.eTX', 's.eTY']).T\n",
    "        shower_frame['signal'] = 1\n",
    "        shower_frame['s.eChi2'] = 0\n",
    "        shower_frame = shower_frame[shower_frame['s.eZ'].isin(z_coordinates)]\n",
    "\n",
    "        numpy_frame = np.asarray(shower_frame)\n",
    "\n",
    "        for i in range(len(z_coordinates)):\n",
    "            for track in numpy_frame[numpy_frame[:, 2] == z_coordinates[i] ,:]:\n",
    "                next_layer = numpy_frame[numpy_frame[:, 2] == z_coordinates[i + 1] ,:]\n",
    "                if (len(next_layer) != 0):\n",
    "                    IP = compute_metric_distance(track, next_layer, classifier = False, IP_mode=True)\n",
    "                    if (IP.min() < 0.001):\n",
    "                        parents.append(track)\n",
    "                        sons.append(next_layer[IP.argmin(), :])\n",
    "\n",
    "    sons = np.asarray(sons)\n",
    "    parents = np.asarray(parents)\n",
    "\n",
    "    noise_sons = list()\n",
    "    noise_parents = list()\n",
    "    for i in range(10):\n",
    "        number = np.random.randint(len(data_to_clear))\n",
    "        track = data_to_clear.iloc[number, :]\n",
    "        track = np.asarray(track)\n",
    "        layer = data_to_clear[data_to_clear['s.eZ'] == track[2] + 1293]\n",
    "        layer = np.asarray(layer)\n",
    "        noise_sons.extend([track] * len(layer))\n",
    "\n",
    "        noise_parents.append(layer)\n",
    "\n",
    "    noise_sons = np.asarray(noise_sons)\n",
    "    noise_parents = np.concatenate(noise_parents)\n",
    "    \n",
    "    signal_part = compute_features(sons, parents)\n",
    "    noise_part = compute_features(noise_sons, noise_parents)\n",
    "    \n",
    "    signal_part = np.insert(signal_part, len(signal_part[0, :]),1,axis = 1)\n",
    "    noise_part = np.insert(noise_part, len(noise_part[0, :]), 0,axis = 1)\n",
    "    \n",
    "    df = np.concatenate([signal_part, noise_part], axis = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "dZ = 205\n",
    "\n",
    "\n",
    "def compute_features(sons, parents):\n",
    "    distance = np.sqrt(np.sum((parents - sons)[:, 0:3]**2, axis = 1))\n",
    "    tan_angle = np.tan(np.arccos(1/(np.sqrt(np.sum((sons - parents)[:, 3:5]**2, axis = 1) + 1))))\n",
    "\n",
    "    angle_z_son = tan_angle\n",
    "    if (len(sons.shape) == 1):\n",
    "        track_begin = sons[0:3]\n",
    "        track_end = np.copy(track_begin)\n",
    "        track_end[0] += dZ * sons[3]\n",
    "        track_end[1] += dZ * sons[4]\n",
    "        track_end[2] += dZ\n",
    "        track_diff = track_end - track_begin\n",
    "        angle_z_son = (dZ ** 2)/(np.linalg.norm(track_diff) * dZ)\n",
    "        angle_z_son = np.asarray([angle_z_son]*len(parents))\n",
    "    else:\n",
    "        track_begin = sons[:, 0:3]\n",
    "\n",
    "        track_end = np.copy(track_begin)\n",
    "        track_end[:, 0] += dZ * sons[:, 3]\n",
    "        track_end[:, 1] += dZ * sons[:, 4]\n",
    "        track_end[:, 2] += dZ\n",
    "        track_diff = track_end - track_begin\n",
    "        angle_z_son = (dZ ** 2)/(np.linalg.norm(track_diff, axis = 1) * dZ)\n",
    "    \n",
    "    \n",
    "    track_diff_par = np.transpose(np.asarray([dZ * parents[:, 3], dZ * parents[:, 4]]))\n",
    "    track_diff_par = np.insert(track_diff_par, 2, dZ, axis = 1)\n",
    "    \n",
    "    \n",
    "    IP = np.linalg.norm(np.cross(parents[:, 0:3] - track_end, parents[:, 0:3] - track_begin), axis = 1)/np.linalg.norm(track_diff)\n",
    "\n",
    "    angle_z_parents = (dZ ** 2)/(np.linalg.norm(track_diff_par, axis = 1) * dZ)\n",
    "    return np.transpose(np.asarray([distance/dZ, tan_angle, IP/dZ, angle_z_son, angle_z_parents]))\n",
    "\n",
    "\n",
    "def compute_metric_distance(track, next_layer, classifier, IP_mode = False):\n",
    "    if (len(next_layer) == 0):\n",
    "        return np.asarray([0])\n",
    "    \n",
    "    X = compute_features(track, next_layer)\n",
    "    if IP_mode == True:\n",
    "        return (X[:, 2]/30)**2\n",
    "\n",
    "    return classifier.predict_proba(X)[:, 1]\n",
    "\n",
    "def find_similar(track, next_layer, classifier, threshold, box_size):\n",
    "    \n",
    "    track = np.array(track, dtype = float)\n",
    "    indexes = np.arange(len(next_layer))\n",
    "    \n",
    "    bool_index = (abs(next_layer[:, 0] - track[0]) < box_size) & (abs(next_layer[:, 1] - track[1]) < box_size)\n",
    "    next_layer = next_layer[bool_index]\n",
    "    indexes = indexes[bool_index]\n",
    "    \n",
    "    dist = compute_metric_distance(track, next_layer, classifier)\n",
    "    result = dist.argmax()\n",
    "    if dist[result] > threshold:\n",
    "        return indexes[result]\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def clear_layer(to_clear, to_compare, classifier, threshold, box_size):\n",
    "    if (len(to_clear) == 0):\n",
    "        return to_clear\n",
    "    result = np.apply_along_axis(find_similar, 1, to_clear, to_compare,  classifier, threshold, box_size)\n",
    "    \n",
    "    to_compare[result[result != -1], 6] = to_clear[result != -1, 6] + 1\n",
    "    to_clear = to_clear[np.logical_or(result != -1, to_clear[:, 6] > 5)]\n",
    "    numbers = np.unique(result[result != -1])\n",
    "    to_compare = to_compare[numbers]\n",
    "\n",
    "    \n",
    "    return np.concatenate([to_clear, to_compare])\n",
    "\n",
    "def shower_finder(data, classifier, number_of_iterations = 1, threshold = 0.98, box_size = 3000):\n",
    "    layers = list(set(data[:, 2]))\n",
    "    layers.sort()\n",
    "    for n in range(number_of_iterations):\n",
    "        for i in range(len(layers) - 1):\n",
    "            cleared_data = clear_layer(data[data[:, 2] == layers[i]], data[data[:, 2] == layers[i+1]], classifier, threshold, box_size)\n",
    "            data = data[(data[:, 2] != layers[i]) & (data[:, 2] != layers[i+1])]\n",
    "            data = np.concatenate([data, cleared_data])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = generate_training_sample(pmc, pbg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm = SVC(C = 0.3, kernel = 'poly', probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(df[:, :5], df[:, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib\n",
    "#joblib.dump(svm, 'svm/svm_5_5.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_coordinates = list(set(pbg['s.eZ']))\n",
    "z_coordinates.sort()\n",
    "def f(x): return x > 60000\n",
    "z_coordinates = filter(f, z_coordinates)\n",
    "\n",
    "data_to_clear = pbg[pbg['s.eZ'].isin(z_coordinates)]\n",
    "data_to_clear = data_to_clear.apply(np.random.permutation)\n",
    "data_to_clear['signal'] = 0\n",
    "data_to_clear = data_to_clear[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shower size: 314\n",
      "Cleared shower size: 71\n",
      "Uncleared noise: 14372\n",
      "\n",
      "CPU times: user 1min 45s, sys: 1.4 s, total: 1min 47s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1):\n",
    "    my_shower = pmc.iloc[15]\n",
    "    my_shower = centralize_shower(my_shower.copy())\n",
    "    shower_frame = pd.DataFrame([\n",
    "                my_shower['BT_X'],\n",
    "                my_shower['BT_Y'],\n",
    "                my_shower['BT_Z'] - my_shower['BT_Z'] % 1293,\n",
    "                my_shower['BT_SX'],\n",
    "                my_shower['BT_SY']],\n",
    "                index=['s.eX', 's.eY', 's.eZ', 's.eTX', 's.eTY']).T\n",
    "    shower_frame['signal'] = 1\n",
    "    shower_frame['s.eChi2'] = 0\n",
    "    \n",
    "    shower_frame = shower_frame[shower_frame['s.eZ'].isin(z_coordinates)]\n",
    "    index=['s.eX', 's.eY', 's.eZ', 's.eTX', 's.eTY', 'signal']\n",
    "    testing_data = pd.concat([shower_frame, data_to_clear])\n",
    "    testing_data = testing_data[index]\n",
    "    testing_data['number_of_ancestors'] = 0\n",
    "    testing_data['parent_index'] = -1\n",
    "    columns = testing_data.columns\n",
    "    testing_data_1 = np.asarray(testing_data)\n",
    "    cleared_data = shower_finder(testing_data_1, number_of_iterations = 3, classifier = svm, box_size = 1000, threshold = 0.975)\n",
    "    cleared_data = pd.DataFrame(cleared_data,columns = columns)\n",
    "    print \"Original shower size: \" + str(len(shower_frame))\n",
    "    print \"Cleared shower size: \" + str(sum(cleared_data.signal == 1))\n",
    "    print \"Uncleared noise: \" + str(sum(cleared_data.signal == 0))\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(slopes): 14443\n"
     ]
    }
   ],
   "source": [
    "%matplotlib osx\n",
    "plot_bg(cleared_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс -- валидация не помогла, и я вернулся к изначальному сценарию. Более качественный датасет тоже сделал всё только хуже. Вероятно дело в том, что меня интересует достаточно специфичный сценарий (отсеить как можно больше шума, при этом пожертвав небольшим количеством сигнала), и обычные метрики качества здесь не подходят.\n",
    "\n",
    "Из картинки видно, что классификатор улучшить сложно, есть множество последовательностей треков, которые выглядят так, как будто их оставила одна частица, и понять, что эта последовательность не относиться к сигналу, достаточно сложно. Более того, их станет ещё больше, когда мы увеличим плотность шума.\n",
    "\n",
    "Я предлагаю попробовать следующую вещь:\n",
    "1. Первоночально пройтись по кирпичу существующим алгроритмом и получить набор последовательностей.\n",
    "2. Пройтись по кирпичу и оставить только последовательность длиннее 5, например (уже должно быть не плохо)\n",
    "3. Далее, если этого будет недостаточно, чтобы увидеть сигнал, мы построим классификатор, который должен будет классифицировать не треки, как раньше, а последовательность целиком. Фичи могут быть: количество треков, расстояние до ближайшей последовательности и тд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def produce_sequences(cleared_data, z_coordinates, classifier):\n",
    "    result_data = cleared_data[cleared_data[:,2] == z_coordinates[0]]\n",
    "    result_data = result_data.reshape((len(result_data),1,len(result_data[0, :])))\n",
    "    \n",
    "    for i in range(len(z_coordinates) - 1):\n",
    "        next_layer = cleared_data[cleared_data[:,2] == z_coordinates[i + 1]]\n",
    "        additional = -np.ones((len(result_data),1,len(result_data[0,0, :])))\n",
    "        \n",
    "        result_data = np.concatenate([result_data, additional], axis = 1)\n",
    "        result = np.apply_along_axis(find_similar, 1, result_data[:,i,:], next_layer,  classifier, 0.95, 1000)\n",
    "        result_data[result != -1, i + 1, :] = next_layer[result[result != -1]]\n",
    "    \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequences = produce_sequences(np.asarray(cleared_data), z_coordinates, classifier = svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length_array = np.zeros(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length_array = length_array.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(sequences)):\n",
    "    length_array[i] = len(sequences[i, :, 0])\n",
    "    for n in range(len(sequences[i, :, 0])):\n",
    "        if sequences[i, n, 0] == -1:\n",
    "            length_array[i] = n\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means_coordinates = np.zeros((len(sequences), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(sequences)):\n",
    "    means_coordinates[i, 0] = np.mean(sequences[i,:length_array[0],0])\n",
    "    means_coordinates[i, 1] = np.mean(sequences[i,:length_array[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = np.array([x for x in 'bgrcmykbgrcmykbgrcmykbgrcmyk'])\n",
    "colors = np.hstack([colors] * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = np.concatenate([means_coordinates, length_array.reshape((len(length_array), 1))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_subset = df[df[:, 2] > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustr = DBSCAN(eps=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=900, leaf_size=30, metric='euclidean',\n",
       "    min_samples=5, p=None, random_state=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustr.fit(df_subset[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = clustr.fit_predict(df_subset[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_subset[:, 0], df_subset[:, 1], color=colors[y_pred].tolist());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_seq = sequences[length_array > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1186, 11, 8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_seq = small_seq.reshape((small_seq.shape[0] * 11, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_seq = small_seq[small_seq[:, 0] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_seq_pd = pd.DataFrame(small_seq,columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(slopes): 3657\n"
     ]
    }
   ],
   "source": [
    "plot_bg(small_seq_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Итак, после первичной обработки данных у нас остается слишком много шума. Более того, сгустки сигнала практически неотличимы от душа. Что мы имеем? 500 объектов, похожих друг на друга. Нас нужно найти небольшое подмножество (~10 объектов), которое отличается лишь тем, что имеет некоторую геометрическую структуру относительно остальных подобных подгрупп.\n",
    " Идея: можно с помощью DBSCAN получить некоторое количество групп. Скажем 20. И после этого пытаться классифицировать их. Какие могут быть фичи: количество объектов, средняя длина, какие нибудь углы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
